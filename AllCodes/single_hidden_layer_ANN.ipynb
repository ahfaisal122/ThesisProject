{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "single hidden layer ANN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qiWSodOIKjk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "813f6f00-77c1-4a9c-cf42-2b88d20a9da2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ykmACXBIY60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0eebbf2b-d095-4a3e-970f-7e5f5d9da8d3"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import cv2\n",
        "\n",
        "import os\n",
        "import random\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, MaxPooling2D, \n",
        "    Dense, Dropout, \n",
        "    Flatten)\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "print(os.listdir(\"/content/gdrive/My Drive/breast-20200512T051500Z-001/breast_data\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['normal', 'cancer']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjRWNCPRZ0RY"
      },
      "source": [
        "IMG_SIZE = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj4_tPeVu6Lg"
      },
      "source": [
        "CATEGORIES = ['cancer', 'normal']\n",
        "dataset = []\n",
        "\n",
        "def generate_data():\n",
        "    for category in CATEGORIES:\n",
        "        path = f'/content/gdrive/My Drive/breast-20200512T051500Z-001/breast_data/{category}'\n",
        "        class_id = CATEGORIES.index(category)\n",
        "        for image in os.listdir(path):\n",
        "            try:\n",
        "                image_array = cv2.imread(os.path.join(path, image), cv2.IMREAD_COLOR)\n",
        "                image_array = cv2.resize(image_array, (IMG_SIZE , IMG_SIZE))\n",
        "                dataset.append([image_array, class_id])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    random.shuffle(dataset)\n",
        "                \n",
        "generate_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsx_EENPu83d"
      },
      "source": [
        "data = []\n",
        "labels = []\n",
        "for features, label in dataset:\n",
        "    data.append(features)\n",
        "    labels.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwiZA-s7vAjW"
      },
      "source": [
        "print(len(dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84J2jRnJvB6N"
      },
      "source": [
        "data = []\n",
        "labels = []\n",
        "for features, label in dataset:\n",
        "    data.append(features)\n",
        "    labels.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4amfmT45vE9k"
      },
      "source": [
        "data = np.array(data)\n",
        "data.reshape(-1, 128, 128, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fod5HFUDZe3-"
      },
      "source": [
        "pickle.dump(data, open(\"data1.pickle\", \"wb\"))\n",
        "\n",
        "pickle.dump(labels, open(\"labels1.pickle\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnlkNLz5ZgG9"
      },
      "source": [
        "data = pickle.load(open(\"data1.pickle\", \"rb\"))\n",
        "\n",
        "labels = pickle.load(open(\"labels1.pickle\", \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCLAwHTjwu8e"
      },
      "source": [
        "train_data, data, train_labels, labels = train_test_split(data, \n",
        "                                                          labels,\n",
        "                                                          test_size=0.15)\n",
        "\n",
        "test_data, validation_data, test_labels, validation_labels = train_test_split(data, \n",
        "                                                                    labels,\n",
        "                                                                    test_size=0.75)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z0U41rthvqE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPNjXgvHwwnB"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "i = 0\n",
        "for i in range(len(test_data)):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(test_data[i])\n",
        "    if(test_labels[i] == 0):\n",
        "        plt.xlabel('Infected')\n",
        "    else:\n",
        "        plt.xlabel('Uninfected')\n",
        "    i += 1\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ARw3xOcw4ki"
      },
      "source": [
        "datagen_train = ImageDataGenerator(rescale=1./255,\n",
        "                            rotation_range=45,\n",
        "                            width_shift_range=0.2,\n",
        "                            height_shift_range=0.2,\n",
        "                            shear_range=0.2,\n",
        "                            zoom_range=0.2,\n",
        "                            horizontal_flip=True)\n",
        "\n",
        "datagen_test = ImageDataGenerator(rescale=1./255)\n",
        "datagen_validation = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFTWUHTZ9Nvu"
      },
      "source": [
        "train_d=datagen_train.fit(train_data)\n",
        "datagen_test.fit(test_data)\n",
        "vod_d=datagen_test.fit(validation_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVFuwpBc7n8Q"
      },
      "source": [
        "model = Sequential([\n",
        "      \n",
        "       Flatten(),\n",
        "       Dense(units=64,kernel_initializer = 'uniform', activation = 'relu',input_shape=(IMG_SIZE,IMG_SIZE,3)) ,\n",
        "       #Dense(units =64, kernel_initializer = 'uniform', activation = 'relu'),\n",
        "       Dense(units =32, kernel_initializer = 'uniform', activation = 'relu'),\n",
        "       #Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'),\n",
        "       Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KJL8UeJ71aH"
      },
      "source": [
        "from tensorflow import keras\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "#model.compile(loss='categorical_crossentropy', optimizer=opt,metrics = ['accuracy'])\n",
        "#model.compile(optimizer =opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4ExUl2578iI"
      },
      "source": [
        "# Fitting the ANN to the Training set\n",
        "#history=model.fit(train_data,y=np.array(train_labels),batch_size = 8, epochs = 100,verbose=1,validation_data=(test_data, np.array(test_labels)))\n",
        "BATCH_SIZE = 32\n",
        "epochs = 30\n",
        "#history=model.fit(train_data, y=np.array(train_labels), batch_size=BATCH_SIZE,epochs=epochs,verbose=1,validation_data=(test_data, np.array(test_labels)))\n",
        "BATCH_SIZE = 32\n",
        "epochs = 30\n",
        "#history=model.fit(train_data, y=np.array(train_labels), batch_size=BATCH_SIZE,epochs=epochs,verbose=1,validation_data=(test_data, np.array(test_labels)))\n",
        "#history=model.fit(train_data,y=np.array(train_labels), batch_size = 10, epochs = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntKwEDICvG8C"
      },
      "source": [
        "accuracy = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "print(f'Training Accuracy: {np.max(accuracy)}')\n",
        "print(f'Training Loss: {np.min(loss)}')\n",
        "print(f'Validation Accuracy: {np.max(val_accuracy)}')\n",
        "print(f'Validation Loss: {np.min(val_loss)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mwkElzE6lwf"
      },
      "source": [
        "epochs_range = range(100)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Accuracy rate')\n",
        "plt.plot(epochs_range, accuracy, label=\"Training Accuracy\")\n",
        "plt.plot(epochs_range, val_accuracy, label=\"Validation Accuracy\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.title(\"Training and Validation Accuracy\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss rate')\n",
        "plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
        "plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C35_l6Fur_5"
      },
      "source": [
        "class_names = ['cancer', 'normal']\n",
        "def plot_images(i, predictions_array, true_labels, images):\n",
        "    predictions_array, true_label, img = predictions_array[i], true_labels[i],images[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    plt.imshow(img)\n",
        "    \n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "        \n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                        100*np.max(predictions_array),\n",
        "                                        class_names[true_label]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCmLlFVf6-CS"
      },
      "source": [
        "random.shuffle(test_data)\n",
        "predictions = model.predict(test_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6XvWV4x6_nA"
      },
      "source": [
        "num_rows = 8\n",
        "num_cols = 6\n",
        "num_images = num_rows * num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(len(test_data)):\n",
        "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "    plot_images(i, predictions, test_labels, test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzxsYWqxl1-E"
      },
      "source": [
        "model.summary( )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt3Lu92Nl7EF"
      },
      "source": [
        "loss , accuracy = model.evaluate( test_data , np.array(test_labels) )\n",
        "print( \"Loss of {}\".format( loss ) , \"Accuracy of {} %\".format( accuracy * 100 ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKeNvZBWmBQ6"
      },
      "source": [
        "pred=model.predict( test_data).argmax( axis=1 ) \n",
        "print ( pred )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4NI7wptG3ro"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "print('F1_score : ',f1_score(test_labels,pred))\n",
        "print('sensitibity : ',metrics.recall_score(test_labels, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCm-wkWPmZ0R"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_labels, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlG_7FWImnhj"
      },
      "source": [
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "fpr , tpr , thresholds = roc_curve (test_labels,pred)\n",
        "plot_roc_curve (fpr,tpr)\n",
        "auc_score=roc_auc_score(test_labels,pred) \n",
        "print(auc_score) \n",
        "print(matthews_corrcoef(test_labels,pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b9QyaSHPK4C"
      },
      "source": [
        "def plot_roc_curve(fpr,tpr): \n",
        "  plt.plot(fpr,tpr) \n",
        "  plt.axis([0,1,0,1]) \n",
        "  plt.xlabel('False Positive Rate') \n",
        "  plt.ylabel('True Positive Rate') \n",
        "  plt.show() \n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtTu-C1wCDTV"
      },
      "source": [
        "confusion = confusion_matrix(test_set.classes, y_pred)\n",
        "TP = confusion[1, 1]\n",
        "TN = confusion[0, 0]\n",
        "FP = confusion[0, 1]\n",
        "FN = confusion[1, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYnmclEgCFQl"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "print('sensitivity =',TP/(TP+FN))\n",
        "print(metrics.recall_score(test_set.classes, y_pred))\n",
        "recall=metrics.recall_score(test_set.classes, y_pred)\n",
        "print('specificity =',TN/(TN+FP))\n",
        "print('F1_score = ',f1_score(test_set.classes,y_pred))\n",
        "#print('F1_score = ',2*((metrics.precision_score(test_set.classes, y_pred)*recall)/(metrics.precision_score(test_set.classes, y_pred)+recall)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdR-w-DTIM4U"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo8FYk0DIN3w"
      },
      "source": [
        "classifier.metrics_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9575E9w6IRXo"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}